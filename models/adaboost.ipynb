{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Daily_Change</th>\n",
       "      <th>Daily_Change_Ind</th>\n",
       "      <th>MACD</th>\n",
       "      <th>...</th>\n",
       "      <th>Open_Gold</th>\n",
       "      <th>Daily_Change_Gold</th>\n",
       "      <th>Daily_Change_Perc_Gold</th>\n",
       "      <th>Increased_Gold</th>\n",
       "      <th>Close/Last_SP500</th>\n",
       "      <th>Open_SP500</th>\n",
       "      <th>Daily_Change_SP500</th>\n",
       "      <th>Daily_Change_Perc_SP500</th>\n",
       "      <th>Increased_SP500</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>793</td>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>15864.099609</td>\n",
       "      <td>15888.400391</td>\n",
       "      <td>13937.299805</td>\n",
       "      <td>14606.500000</td>\n",
       "      <td>12336499712</td>\n",
       "      <td>-1232.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>636.405515</td>\n",
       "      <td>...</td>\n",
       "      <td>1292.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>1</td>\n",
       "      <td>2687.54</td>\n",
       "      <td>2686.10</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>908</td>\n",
       "      <td>2018-06-14</td>\n",
       "      <td>6342.750000</td>\n",
       "      <td>6707.140137</td>\n",
       "      <td>6334.459961</td>\n",
       "      <td>6675.350098</td>\n",
       "      <td>5138710016</td>\n",
       "      <td>325.450196</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-383.201570</td>\n",
       "      <td>...</td>\n",
       "      <td>1303.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.003990</td>\n",
       "      <td>1</td>\n",
       "      <td>2782.49</td>\n",
       "      <td>2783.21</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>-0.000259</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>224</td>\n",
       "      <td>2015-09-25</td>\n",
       "      <td>234.362000</td>\n",
       "      <td>237.427002</td>\n",
       "      <td>233.684006</td>\n",
       "      <td>235.143997</td>\n",
       "      <td>22363600</td>\n",
       "      <td>0.614990</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.731076</td>\n",
       "      <td>...</td>\n",
       "      <td>1151.0</td>\n",
       "      <td>-5.4</td>\n",
       "      <td>-0.004692</td>\n",
       "      <td>0</td>\n",
       "      <td>1931.34</td>\n",
       "      <td>1935.93</td>\n",
       "      <td>-4.59</td>\n",
       "      <td>-0.002371</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1042</td>\n",
       "      <td>2018-12-26</td>\n",
       "      <td>3819.666748</td>\n",
       "      <td>3893.359619</td>\n",
       "      <td>3769.863770</td>\n",
       "      <td>3857.297607</td>\n",
       "      <td>5326547918</td>\n",
       "      <td>41.806884</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-83.043066</td>\n",
       "      <td>...</td>\n",
       "      <td>1273.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.000393</td>\n",
       "      <td>0</td>\n",
       "      <td>2467.70</td>\n",
       "      <td>2363.12</td>\n",
       "      <td>104.58</td>\n",
       "      <td>0.044255</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>563</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>920.958984</td>\n",
       "      <td>972.018982</td>\n",
       "      <td>920.958984</td>\n",
       "      <td>970.403015</td>\n",
       "      <td>164582000</td>\n",
       "      <td>50.020996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.846431</td>\n",
       "      <td>...</td>\n",
       "      <td>1197.7</td>\n",
       "      <td>13.7</td>\n",
       "      <td>0.011439</td>\n",
       "      <td>1</td>\n",
       "      <td>2278.87</td>\n",
       "      <td>2274.02</td>\n",
       "      <td>4.85</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date          Open          High           Low  \\\n",
       "0         793  2017-12-28  15864.099609  15888.400391  13937.299805   \n",
       "1         908  2018-06-14   6342.750000   6707.140137   6334.459961   \n",
       "2         224  2015-09-25    234.362000    237.427002    233.684006   \n",
       "3        1042  2018-12-26   3819.666748   3893.359619   3769.863770   \n",
       "4         563  2017-01-31    920.958984    972.018982    920.958984   \n",
       "\n",
       "          Close       Volume  Daily_Change  Daily_Change_Ind        MACD  ...  \\\n",
       "0  14606.500000  12336499712  -1232.000000               0.0  636.405515  ...   \n",
       "1   6675.350098   5138710016    325.450196               1.0 -383.201570  ...   \n",
       "2    235.143997     22363600      0.614990               1.0   -1.731076  ...   \n",
       "3   3857.297607   5326547918     41.806884               1.0  -83.043066  ...   \n",
       "4    970.403015    164582000     50.020996               1.0   12.846431  ...   \n",
       "\n",
       "   Open_Gold  Daily_Change_Gold  Daily_Change_Perc_Gold  Increased_Gold  \\\n",
       "0     1292.0                5.2                0.004025               1   \n",
       "1     1303.1                5.2                0.003990               1   \n",
       "2     1151.0               -5.4               -0.004692               0   \n",
       "3     1273.5               -0.5               -0.000393               0   \n",
       "4     1197.7               13.7                0.011439               1   \n",
       "\n",
       "   Close/Last_SP500  Open_SP500  Daily_Change_SP500  Daily_Change_Perc_SP500  \\\n",
       "0           2687.54     2686.10                1.44                 0.000536   \n",
       "1           2782.49     2783.21               -0.72                -0.000259   \n",
       "2           1931.34     1935.93               -4.59                -0.002371   \n",
       "3           2467.70     2363.12              104.58                 0.044255   \n",
       "4           2278.87     2274.02                4.85                 0.002133   \n",
       "\n",
       "   Increased_SP500  label  \n",
       "0                1    0.0  \n",
       "1                0    0.0  \n",
       "2                0    1.0  \n",
       "3                1    1.0  \n",
       "4                1    1.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = pd.read_csv(\"bitcoin_train.csv\")\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Daily_Change', 'Daily_Change_Ind', 'MACD', 'PROC_3', 'PROC_5', 'PROC_10', 'wpr', 'sto_os', 'goog_trend_score', 'count', 'compound', 'retweets_count', 'likes_count', 'replies_count', 'compound_weighted_replies', 'compound_weighted_likes', 'compound_weighted_retweets', 'Daily_Change_Perc', 'Daily_Change_Gold', 'Daily_Change_Perc_Gold', 'Increased_Gold', 'Daily_Change_SP500', 'Daily_Change_Perc_SP500', 'Increased_SP500']\n",
      "label\n"
     ]
    }
   ],
   "source": [
    "features_df.columns\n",
    "\n",
    "feature_lst = ['Daily_Change', 'Daily_Change_Ind', 'MACD', 'PROC_3', 'PROC_5','PROC_10', 'wpr',\\\n",
    "                'sto_os', 'goog_trend_score', 'count', 'compound', 'retweets_count', 'likes_count', 'replies_count',\\\n",
    "                'compound_weighted_replies', 'compound_weighted_likes','compound_weighted_retweets',\\\n",
    "                'Daily_Change_Perc', 'Daily_Change_Gold', 'Daily_Change_Perc_Gold', 'Increased_Gold', \\\n",
    "                'Daily_Change_SP500', 'Daily_Change_Perc_SP500', 'Increased_SP500']\n",
    "\n",
    "outcome = features_df.columns[-1]\n",
    "\n",
    "print(feature_lst)\n",
    "print(outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1253, 24) (1253,)\n"
     ]
    }
   ],
   "source": [
    "X = features_df[feature_lst]\n",
    "y = features_df[outcome]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth: 1 , Score: 0.6327555555555555\n",
      "Depth: 2 , Score: 0.6455619047619047\n",
      "Depth: 3 , Score: 0.6512507936507935\n",
      "Depth: 4 , Score: 0.646431746031746\n",
      "Depth: 5 , Score: 0.6440253968253967\n",
      "Depth: 6 , Score: 0.6313523809523809\n",
      "Depth: 7 , Score: 0.6184888888888889\n",
      "Depth: 8 , Score: 0.6025269841269841\n",
      "Depth: 9 , Score: 0.5969523809523809\n",
      "Depth: 10 , Score: 0.6049015873015873\n",
      "Max depth should be: 3\n"
     ]
    }
   ],
   "source": [
    "# Figure out what the tree depth should be (maximum score)\n",
    "results_dict = {}\n",
    "cx_validation = KFold(n_splits = 10, shuffle = True, random_state = 1)\n",
    "for depth in range(1, 11):\n",
    "    base_estimator = DecisionTreeClassifier(max_depth = depth, random_state = 1234)\n",
    "    if base_estimator.fit(X,y).tree_.max_depth < depth:\n",
    "        break\n",
    "    accuracy_score = np.mean(cross_val_score(base_estimator, X, y, cv = cx_validation, scoring = 'accuracy', n_jobs = 1))\n",
    "    print(\"Depth:\", depth, \", Score:\", accuracy_score)\n",
    "\n",
    "    results_dict[depth] = accuracy_score\n",
    "\n",
    "max_val = -1\n",
    "max_depth_val = None\n",
    "for key, val in results_dict.items():\n",
    "    if val > max_val:\n",
    "        max_val = val\n",
    "        max_depth_val = key\n",
    "\n",
    "print(\"Max depth should be:\", max_depth_val)\n",
    "\n",
    "    # https://educationalresearchtechniques.com/2019/01/02/adaboost-classification-in-python/\n",
    "    # https://towardsdatascience.com/boosting-and-adaboost-clearly-explained-856e21152d3e\n",
    "    # https://python-bloggers.com/2019/01/adaboost-classification-in-python/ # this one for \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create adaboost classifer object\n",
    "base_estimator = DecisionTreeClassifier(max_depth = max_depth_val, random_state = 1234)\n",
    "\n",
    "adaboost = AdaBoostClassifier(base_estimator = base_estimator, n_estimators = 20,\n",
    "                              learning_rate = 1, random_state = 1234)\n",
    "\n",
    "# Train Adaboost Classifer\n",
    "model = adaboost.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for valid dataset\n",
    "y_hat = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.589171974522293\n",
      "MSE: 0.410828025477707\n",
      "CONFUSION: [[ 75  61]\n",
      " [ 68 110]]\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy with chosen decision tree depth and randomly chosen hyperparameters\n",
    "accuracy_score = metrics.accuracy_score(y_valid, y_hat)\n",
    "mse = metrics.mean_squared_error(y_valid, y_hat)\n",
    "confusion = metrics.confusion_matrix(y_valid, y_hat) \n",
    "\n",
    "print(\"Accuracy:\", accuracy_score)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"CONFUSION:\", confusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ksarussi/.local/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0.   0.   0.1  0.05 0.15 0.05 0.   0.05 0.05 0.   0.05 0.05 0.   0.\n 0.1  0.05 0.   0.15 0.05 0.05 0.   0.05 0.   0.  ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/ksarussi/wsl/capp-ml/ml-proj-ksarussi/crypto-currency/models/adaboost.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/ksarussi/wsl/capp-ml/ml-proj-ksarussi/crypto-currency/models/adaboost.ipynb#ch0000019vscode-remote?line=0'>1</a>\u001b[0m \u001b[39m# ask irsa about this part\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/home/ksarussi/wsl/capp-ml/ml-proj-ksarussi/crypto-currency/models/adaboost.ipynb#ch0000019vscode-remote?line=1'>2</a>\u001b[0m new \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(adaboost\u001b[39m.\u001b[39;49mfeature_importances_)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py:679\u001b[0m, in \u001b[0;36mAdaBoostClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py?line=661'>662</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py?line=662'>663</a>\u001b[0m     \u001b[39m\"\"\"Predict classes for X.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py?line=663'>664</a>\u001b[0m \n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py?line=664'>665</a>\u001b[0m \u001b[39m    The predicted class of an input sample is computed as the weighted mean\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py?line=676'>677</a>\u001b[0m \u001b[39m        The predicted classes.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py?line=677'>678</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py?line=678'>679</a>\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecision_function(X)\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py?line=680'>681</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py?line=681'>682</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(pred \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py:740\u001b[0m, in \u001b[0;36mAdaBoostClassifier.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py?line=720'>721</a>\u001b[0m \u001b[39m\"\"\"Compute the decision function of ``X``.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py?line=721'>722</a>\u001b[0m \n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py?line=722'>723</a>\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py?line=736'>737</a>\u001b[0m \u001b[39m    class in ``classes_``, respectively.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py?line=737'>738</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py?line=738'>739</a>\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py?line=739'>740</a>\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_X(X)\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py?line=741'>742</a>\u001b[0m n_classes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py?line=742'>743</a>\u001b[0m classes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_[:, np\u001b[39m.\u001b[39mnewaxis]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py:82\u001b[0m, in \u001b[0;36mBaseWeightBoosting._check_X\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py?line=79'>80</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_X\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m     <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py?line=80'>81</a>\u001b[0m     \u001b[39m# Only called to validate X in non-fit methods, therefore reset=False\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py?line=81'>82</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m     <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py?line=82'>83</a>\u001b[0m         X,\n\u001b[1;32m     <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py?line=83'>84</a>\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py?line=84'>85</a>\u001b[0m         ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py?line=85'>86</a>\u001b[0m         allow_nd\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py?line=86'>87</a>\u001b[0m         dtype\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py?line=87'>88</a>\u001b[0m         reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/ensemble/_weight_boosting.py?line=88'>89</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:566\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/base.py?line=563'>564</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/base.py?line=564'>565</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/base.py?line=565'>566</a>\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/base.py?line=566'>567</a>\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/base.py?line=567'>568</a>\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:769\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/utils/validation.py?line=766'>767</a>\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/utils/validation.py?line=767'>768</a>\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/utils/validation.py?line=768'>769</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/utils/validation.py?line=769'>770</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/utils/validation.py?line=770'>771</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/utils/validation.py?line=771'>772</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/utils/validation.py?line=772'>773</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/utils/validation.py?line=773'>774</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/utils/validation.py?line=775'>776</a>\u001b[0m \u001b[39m# make sure we actually converted to numeric:\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/ksarussi/.local/lib/python3.8/site-packages/sklearn/utils/validation.py?line=776'>777</a>\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mOUSV\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0.   0.   0.1  0.05 0.15 0.05 0.   0.05 0.05 0.   0.05 0.05 0.   0.\n 0.1  0.05 0.   0.15 0.05 0.05 0.   0.05 0.   0.  ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# ask irsa about this part\n",
    "# new = model.predict(adaboost.feature_importances_)\n",
    "# for i in range(len(feature_lst)):\n",
    "#     print(f\"{feature_lst[i]}: {feature_import[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyper parametertuning (number estimators and learning rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parametertuning (number estimators and learning rate)\n",
    "ada = AdaBoostClassifier()\n",
    "search_grid = {'n_estimators':[500,1000,2000], 'learning_rate':[.001,0.01,.1]}\n",
    "search = GridSearchCV(estimator = ada, param_grid = search_grid, scoring = 'accuracy', n_jobs = 1, cv = cx_validation)\n",
    "\n",
    "#https://python-bloggers.com/2019/01/adaboost-classification-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.fit(X,y)\n",
    "search.best_params_\n",
    "print(search.best_params_)\n",
    "search.best_score_\n",
    "print(search.best_score_)\n",
    "#Out[34]: 0.7425149700598802\n",
    "\n",
    "\n",
    "\n",
    "# https://python-bloggers.com/2019/01/adaboost-classification-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6472126984126984"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = np.mean(cross_val_score(ada, X, y, scoring='accuracy', cv = cx_validation, n_jobs = 1))\n",
    "score\n",
    "\n",
    "\n",
    "#https://python-bloggers.com/2019/01/adaboost-classification-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.681812 using {'learning_rate': 0.01, 'n_estimators': 500}\n",
      "0.640842 (0.034224) with: {'learning_rate': 0.001, 'n_estimators': 10}\n",
      "0.644830 (0.031782) with: {'learning_rate': 0.001, 'n_estimators': 50}\n",
      "0.648298 (0.031138) with: {'learning_rate': 0.001, 'n_estimators': 100}\n",
      "0.670358 (0.042053) with: {'learning_rate': 0.001, 'n_estimators': 500}\n",
      "0.677280 (0.037879) with: {'learning_rate': 0.001, 'n_estimators': 1000}\n",
      "0.643767 (0.030720) with: {'learning_rate': 0.01, 'n_estimators': 10}\n",
      "0.670093 (0.041589) with: {'learning_rate': 0.01, 'n_estimators': 50}\n",
      "0.677280 (0.037879) with: {'learning_rate': 0.01, 'n_estimators': 100}\n",
      "0.681812 (0.033829) with: {'learning_rate': 0.01, 'n_estimators': 500}\n",
      "0.678356 (0.037315) with: {'learning_rate': 0.01, 'n_estimators': 1000}\n",
      "0.679943 (0.039659) with: {'learning_rate': 0.1, 'n_estimators': 10}\n",
      "0.680222 (0.034767) with: {'learning_rate': 0.1, 'n_estimators': 50}\n",
      "0.679689 (0.037879) with: {'learning_rate': 0.1, 'n_estimators': 100}\n",
      "0.674343 (0.041509) with: {'learning_rate': 0.1, 'n_estimators': 500}\n",
      "0.662902 (0.048804) with: {'learning_rate': 0.1, 'n_estimators': 1000}\n",
      "0.660783 (0.040680) with: {'learning_rate': 1.0, 'n_estimators': 10}\n",
      "0.657331 (0.037030) with: {'learning_rate': 1.0, 'n_estimators': 50}\n",
      "0.647490 (0.038654) with: {'learning_rate': 1.0, 'n_estimators': 100}\n",
      "0.623287 (0.042588) with: {'learning_rate': 1.0, 'n_estimators': 500}\n",
      "0.610800 (0.041446) with: {'learning_rate': 1.0, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "# https://machinelearningmastery.com/adaboost-ensemble-in-python/\n",
    "\n",
    "# alternative way to check n_estiamtors and learning_Rate\n",
    "model = AdaBoostClassifier()\n",
    "# define the grid of values to search\n",
    "grid = dict()\n",
    "grid['n_estimators'] = [10, 50, 100, 500, 1000]\n",
    "grid['learning_rate'] = [0.001, 0.01, 0.1, 1.0]\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define the grid search procedure\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy')\n",
    "# execute the grid search\n",
    "grid_result = grid_search.fit(X, y)\n",
    "# summarize the best score and configuration\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "# summarize all scores that were evaluated\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerun adaboost with chosen hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chosen_n 500\n",
      "chosen_learing_rate 0.01\n"
     ]
    }
   ],
   "source": [
    "base_estimator = DecisionTreeClassifier(max_depth = max_depth_val, random_state = 1234)\n",
    "\n",
    "chosen_learning_rate = list(grid_result.best_params_.values())[0]\n",
    "chosen_n = list(grid_result.best_params_.values())[1]\n",
    "\n",
    "print(\"chosen_n\", chosen_n)\n",
    "print(\"chosen_learing_rate\", chosen_learning_rate)\n",
    "\n",
    "adaboost = AdaBoostClassifier(base_estimator = base_estimator, n_estimators = chosen_n,\n",
    "                              learning_rate = chosen_learning_rate, random_state = 1234)\n",
    "\n",
    "# Train Adaboost Classifer\n",
    "model = adaboost.fit(X_train, y_train)\n",
    "\n",
    "# Predict the response for valid dataset\n",
    "y_hat = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6401273885350318\n",
      "MSE: 0.35987261146496813\n",
      "CONFUSION: [[ 79  57]\n",
      " [ 56 122]]\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy with chosen decision tree depth and chosen hyperparameters\n",
    "accuracy_score = metrics.accuracy_score(y_valid, y_hat)\n",
    "mse = metrics.mean_squared_error(y_valid, y_hat)\n",
    "confusion = metrics.confusion_matrix(y_valid, y_hat) \n",
    "\n",
    "print(\"Accuracy:\", accuracy_score)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"CONFUSION:\", confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' other links\n",
    "https://inria.github.io/scikit-learn-mooc/python_scripts/ensemble_adaboost.html\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
    " https://scikit-learn.org/stable/tutorial/statistical_inference/model_selection.html\n",
    " https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n",
    " \n",
    " https://towardsdatascience.com/how-do-you-implement-adaboost-with-python-a76427b0fa7a\n",
    " https://towardsdatascience.com/machine-learning-part-17-boosting-algorithms-adaboost-in-python-d00faac6c464\n",
    " \n",
    " https://machinelearningmastery.com/adaboost-ensemble-in-python/\n",
    " https://machinelearningmastery.com/k-fold-cross-validation/\n",
    "\n",
    " https://medium.datadriveninvestor.com/understanding-adaboost-and-scikit-learns-algorithm-c8d8af5ace10\n",
    " https://blog.paperspace.com/adaboost-optimizer/\n",
    " https://www.datacamp.com/tutorial/adaboost-classifier-python\n",
    " https://educationalresearchtechniques.com/2019/01/02/adaboost-classification-in-python/\n",
    "\n",
    " consider trying standardization https://github.com/mehuls45/Heart-Disease-prediction-using-ML/blob/master/AdaBoost.ipynb\n",
    "\n",
    " # no need to normalize/standardize in ensemble methods \n",
    " https://towardsdatascience.com/the-ultimate-guide-to-adaboost-random-forests-and-xgboost-7f9327061c4f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat for Dogecoin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.read_csv(\"bitcoin_train.csv\")\n",
    "features_df.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
